# データ分析デモプロジェクト計画書

**プロジェクト名**: Skills & Agents ハイブリッドデータ分析デモ
**作成日**: 2025-11-15
**目的**: Claude Code SkillsとAgentsを組み合わせたデータ分析のベストプラクティスを実践

---

## 目次

1. [プロジェクト概要](#プロジェクト概要)
2. [ビジネス背景](#ビジネス背景)
3. [ダミーデータ仕様](#ダミーデータ仕様)
4. [プロジェクト構造](#プロジェクト構造)
5. [分析ワークフロー（5フェーズ）](#分析ワークフロー5フェーズ)
6. [エージェント定義](#エージェント定義)
7. [期待される成果物](#期待される成果物)
8. [確認事項・質問](#確認事項質問)

---

## プロジェクト概要

### 目標

1. **ベストプラクティスの実践**: `data_analysis_skills_agents_best_practices.md`で定義した手法を実際に適用
2. **ハイブリッドアプローチの検証**: SkillsとAgentsを組み合わせた分析の有効性を実証
3. **再利用可能なテンプレート作成**: 他のデータ分析プロジェクトで活用できるテンプレートを構築

### デモのシナリオ

**ビジネス課題**:
「過去3年間の売上データから、売上改善のためのアクション可能なインサイトを抽出したい」

**分析手法**:
5フェーズワークフロー（Sequential Flow + Role-Based Division）

---

## ビジネス背景

### 企業プロフィール

- **企業名**: Umami Wholesale Inc.（仮想企業）
- **業種**: 日本食材卸売業
- **事業地域**: アメリカ全土
- **主要顧客**: 日本食レストラン、アジアンスーパー、オンラインマーケットプレイス
- **設立**: 2020年
- **従業員数**: 約50名

### ビジネスモデル

- **仕入先**: 日本の食品メーカー（キッコーマン、ヤマサ、ハウス食品、日清食品等）
- **販売チャネル**: B2B卸売、オンライン直販
- **物流**: 西海岸、東海岸に倉庫を保有

### ビジネス環境（2022-2024）

- **2022年**: COVID-19の影響が残る中、レストラン需要が回復基調
- **2023年**: インフレによる価格上昇、円安の影響
- **2024年**: 日本食ブームの継続、健康志向の高まり

---

## ダミーデータ仕様

### データ期間

- **開始日**: 2022-01-01
- **終了日**: 2024-12-31
- **総レコード数**: 約30,000-50,000行（日次×商品×地域×顧客タイプ）

### データ項目

| 項目名 | データ型 | 説明 | 例 |
|--------|----------|------|-----|
| `date` | Date | 販売日 | 2022-01-15 |
| `product_category` | String | 商品カテゴリ | Soy Sauce, Miso, Rice |
| `product_name` | String | 商品名 | Kikkoman Soy Sauce 1L |
| `region` | String | 販売地域 | West Coast, East Coast, Midwest, South |
| `customer_type` | String | 顧客タイプ | Restaurant, Retail Store, Online |
| `quantity_sold` | Integer | 販売数量 | 120 |
| `unit_price` | Float | 単価（USD） | 8.99 |
| `total_sales` | Float | 売上金額（USD） | 1078.80 |
| `cost_of_goods` | Float | 仕入原価（USD） | 647.28 |
| `promotion_flag` | Boolean | プロモーション有無 | True/False |
| `day_of_week` | String | 曜日 | Monday |
| `month` | Integer | 月 | 1 |
| `quarter` | Integer | 四半期 | 1 |
| `year` | Integer | 年 | 2022 |

### 商品カテゴリ（8カテゴリ）

1. **Soy Sauce（醤油）**: Kikkoman, Yamasa
2. **Miso（味噌）**: Marukome, Hikari
3. **Rice（米）**: Koshihikari, Calrose
4. **Noodles（麺類）**: Ramen, Udon, Soba
5. **Seasonings（調味料）**: Mirin, Sake, Dashi
6. **Frozen Foods（冷凍食品）**: Gyoza, Edamame
7. **Snacks（スナック菓子）**: Pocky, Senbei, Mochi
8. **Beverages（飲料）**: Green Tea, Ramune

### 地域分布（4地域）

1. **West Coast**: カリフォルニア中心（40%）- 日本食需要大
2. **East Coast**: ニューヨーク中心（30%）
3. **Midwest**: シカゴ、デトロイト等（15%）
4. **South**: テキサス、フロリダ等（15%）

### 顧客タイプ（3タイプ）

1. **Restaurant**: 日本食レストラン（50%）
2. **Retail Store**: アジアンスーパー（30%）
3. **Online**: オンライン販売（20% - 増加傾向）

### データパターン・特徴

#### 季節性パターン

- **1月**: 正月需要で米、醤油、麺類が増加（+30%）
- **3-5月**: 春のプロモーション期間
- **7-8月**: お盆需要、夏季冷凍食品増加
- **11-12月**: 感謝祭・年末需要でスナック、飲料増加

#### トレンド

- **全体**: 年間成長率 +8-12%
- **オンライン顧客**: 年間成長率 +25%（急成長）
- **West Coast**: 安定成長
- **South**: 新規市場開拓で高成長（+15%）

#### 異常値・イベント

- **2022年3月**: COVID-19規制緩和でレストラン需要急増
- **2023年6月**: サプライチェーン問題で一時的な在庫不足
- **2024年2月**: 日本食フェスティバルで売上スパイク

#### プロモーション効果

- プロモーション期間中: 売上 +20-40%
- プロモーション頻度: 月1-2回

---

## プロジェクト構造

```
demo-data-analysis/
├── README.md                          # プロジェクト概要
├── PROJECT_PLAN.md                    # この計画書
├── data/
│   ├── raw/
│   │   └── umami_sales_2022_2024.csv  # 生データ
│   └── processed/                      # 加工済みデータ（分析中に生成）
├── analysis/
│   ├── phase1_eda/                     # Phase 1: 基礎分析（Skill）
│   │   ├── eda_report.html
│   │   └── data_quality_report.md
│   ├── phase2_patterns/                # Phase 2: パターン発見（Agent）
│   │   ├── pattern_analysis.md
│   │   └── business_hypotheses.md
│   ├── phase3_visualizations/          # Phase 3: 詳細可視化（Skill）
│   │   ├── sales_trends.html
│   │   └── category_analysis.html
│   ├── phase4_validation/              # Phase 4: 仮説検証（Agent）
│   │   └── hypothesis_validation.md
│   └── phase5_summary/                 # Phase 5: エグゼクティブサマリー（Agent）
│       └── executive_summary.md
├── scripts/
│   └── generate_dummy_data.py          # ダミーデータ生成スクリプト
└── .agents/
    └── data-analysis-expert/           # カスタムエージェント定義
        └── AGENT.md
```

---

## 分析ワークフロー（5フェーズ）

### Phase 1: 基礎分析（Skill）

**使用**: `Skill(data-scientist)`

**実施内容**:
- データ品質チェック（欠損値、異常値、データ型）
- 基本統計量（平均、中央値、標準偏差、四分位数）
- 相関分析（売上と各変数の相関）
- 分布の可視化（ヒストグラム、箱ひげ図）
- 時系列プロット（月次・四半期売上トレンド）

**成果物**:
- `eda_report.html` - 包括的なEDAレポート
- `data_quality_report.md` - データ品質評価

**期待される所要時間**: 10-15分

---

### Phase 2: パターン発見（Agent）

**使用**: `Agent(data-analysis-expert)` または `Agent(general-purpose)`

**実施内容**:
1. 売上の季節性パターンを特定
2. 売上が急増/急減した期間を検出（異常検出）
3. 商品カテゴリ別の傾向を分析
4. 地域別の特徴を抽出
5. 顧客タイプ別の購買行動を分析
6. プロモーション効果の測定
7. ビジネス仮説を3-5個生成

**成果物**:
- `pattern_analysis.md` - パターン分析レポート
- `business_hypotheses.md` - ビジネス仮説リスト

**期待される所要時間**: 15-20分

---

### Phase 3: 詳細可視化（Skill）

**使用**: `Skill(data-visualization-expert)`

**実施内容**:
- Phase 2で発見したパターンを可視化
- 月別売上トレンド（折れ線グラフ）
- カテゴリ別構成比（積み上げ棒グラフ、円グラフ）
- 地域別ヒートマップ
- 顧客タイプ別トレンド
- プロモーション効果の可視化

**成果物**:
- `sales_trends.html` - 売上トレンド可視化
- `category_analysis.html` - カテゴリ別分析可視化

**期待される所要時間**: 10-15分

---

### Phase 4: 仮説検証（Agent）

**使用**: `Agent(data-analysis-expert)` または `Agent(general-purpose)`

**実施内容**:
Phase 2で生成した仮説を統計的に検証:
1. 「West Coastの売上は他地域より20%高い」→ t検定
2. 「オンライン顧客の成長率は年間25%以上」→ トレンド分析
3. 「プロモーション期間中は売上が30%増加」→ 前後比較分析
4. 「正月（1月）の売上は平均月の1.5倍」→ 月別比較
5. 「冷凍食品は夏季（7-8月）に売上増加」→ 季節性検定

**成果物**:
- `hypothesis_validation.md` - 仮説検証レポート

**期待される所要時間**: 15-20分

---

### Phase 5: アクション提案（Agent）

**使用**: `Agent(data-analysis-expert)` または `Agent(general-purpose)`

**実施内容**:
Phase 1-4の分析結果を統合し、経営判断用レポート作成:
1. 主要な発見（Top 5）
2. ビジネスインパクト評価
3. 具体的なアクション提案（優先度付き）
   - 例：「South地域への投資拡大」「オンラインチャネル強化」
4. 期待される効果（定量的に）
5. リスクと制約条件
6. 次のステップ

**成果物**:
- `executive_summary.md` - エグゼクティブサマリー

**期待される所要時間**: 10-15分

---

## エージェント定義

### カスタムエージェント: `data-analysis-expert`

**目的**: データ分析のベストプラクティスに特化したエージェント

**定義ファイル**: `.agents/data-analysis-expert/AGENT.md`

**特徴**:
- SkillsとAgentsの使い分けを理解
- データ分析ワークフローに精通
- ビジネスインサイト抽出に強い
- 統計的検証とビジネス解釈の両方が可能

**詳細**: 後述のエージェント定義ファイルで定義

---

## 期待される成果物

### 1. ダミーデータ

- `data/raw/umami_sales_2022_2024.csv` (30,000-50,000行)

### 2. 分析レポート（5フェーズ）

- Phase 1: `eda_report.html`, `data_quality_report.md`
- Phase 2: `pattern_analysis.md`, `business_hypotheses.md`
- Phase 3: `sales_trends.html`, `category_analysis.html`
- Phase 4: `hypothesis_validation.md`
- Phase 5: `executive_summary.md`

### 3. スクリプト

- `generate_dummy_data.py` - データ生成スクリプト

### 4. エージェント定義

- `.agents/data-analysis-expert/AGENT.md`

### 5. ドキュメント

- `README.md` - プロジェクト概要とデモ実行方法
- `PROJECT_PLAN.md` - この計画書

---

## 確認事項・質問

### 1. ダミーデータの詳細仕様

**質問A: データの粒度**
- 日次データで良いですか？
- それとも、より細かい（時間単位、トランザクション単位）データが必要ですか？
- **推奨**: 日次データ（シンプルで分析しやすい）

**質問B: データ件数**
- 30,000-50,000行で十分ですか？
- より大規模なデータセット（10万行以上）が必要ですか？
- **推奨**: 3年×365日×8カテゴリ×4地域×3顧客タイプ = 約105,000行（集計後30,000-50,000行）

**質問C: 商品の詳細度**
- カテゴリレベル（8カテゴリ）で良いですか？
- 各カテゴリに複数の商品（例：醤油に5-10種類の商品）を含めますか？
- **推奨**: カテゴリ + 代表的な商品名（各カテゴリ2-3商品）で、合計20-25商品

---

### 2. 分析の深さ

**質問D: 統計的検定のレベル**
- 基本的な検定（t検定、カイ二乗検定）で十分ですか？
- より高度な分析（時系列予測、機械学習モデル）も含めますか？
- **推奨**: 基本的な検定 + 簡単なトレンド分析（ベストプラクティスのデモに集中）

**質問E: 可視化の種類**
- 基本的なグラフ（折れ線、棒、円）で十分ですか？
- インタラクティブな可視化（Plotly等）も含めますか？
- **推奨**: 静的な可視化（Matplotlib/Seaborn）でOK（再現性重視）

---

### 3. エージェント定義

**質問F: エージェントの専門性**
- 汎用的な`data-analysis-expert`エージェント1つで良いですか？
- 役割別に複数のエージェント（pattern-finder, hypothesis-validator等）を定義しますか？
- **推奨**: 1つの`data-analysis-expert`エージェント（シンプルさ重視）

---

### 4. デモの実行方法

**質問G: 自動化レベル**
- 5フェーズを自動的に順次実行するスクリプトが必要ですか？
- それとも、各フェーズを手動で実行（よりインタラクティブ）しますか？
- **推奨**: 手動実行（各フェーズの結果を確認しながら進める）

**質問H: デモの所要時間**
- 全5フェーズの実行に60-90分で良いですか？
- より短時間（30分以内）で完了できるようにしますか？
- **推奨**: 60-90分（じっくり各フェーズを理解）

---

### 5. ビジネスシナリオの詳細

**質問I: 分析の焦点**
以下のうち、特に重点を置くべき分析観点はありますか？
- A. 地域別の売上拡大戦略
- B. 商品カテゴリの最適化
- C. オンラインチャネルの成長戦略
- D. 季節性を活用したプロモーション最適化
- E. すべてバランス良く

**推奨**: E（すべてバランス良く）→ ベストプラクティスのデモとして網羅的に

---

## 次のステップ（質問回答後）

上記の確認事項にご回答いただいた後、以下の順序で進めます：

1. ✅ 質問への回答を反映してこの計画書を更新
2. ダミーデータ生成スクリプトを作成・実行
3. エージェント定義ファイルを作成
4. フォルダ構造を完全に構築
5. README.mdを作成（デモ実行ガイド）
6. Phase 1から順次、分析を実行

---

**作成日**: 2025-11-15
**最終更新**: 2025-11-15
**バージョン**: 1.0（初版・レビュー待ち）
